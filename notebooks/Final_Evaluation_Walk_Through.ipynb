{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One run final walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the full run walkthrough on the large data set\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refractor the source code and bring it to individual scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure a full run through with one click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your base path is at: DataScience'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check some parameters\n",
    "## depending where you launch your notebook, the relative path might not work\n",
    "## you should start the notebook server from your base path\n",
    "## when opening the notebook, typically your path will be ../ads_covid-19/notebooks\n",
    "import os\n",
    "if os.path.split(os.getcwd())[-1]=='notebooks':\n",
    "    os.chdir(\"../\")\n",
    "\n",
    "'Your base path is at: '+os.path.split(os.getcwd())[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Update all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error : b''\n",
      "out : b'Already up to date.\\n'\n"
     ]
    }
   ],
   "source": [
    "# %load C:\\Users\\Nitin\\ds-covid19\\src\\data\\get_data.py\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "if os.path.split(os.getcwd())[-1]=='notebooks':\n",
    "    os.chidr(\"../\")\n",
    "\n",
    "def get_johns_hopkins():\n",
    "    git_pull = subprocess.Popen(\"git pull\" ,\n",
    "                                cwd = os.path.dirname('C:/Users/Nitin/ds-covid19/data/raw/COVID-19/'),\n",
    "                                shell = True,\n",
    "                                stdout = subprocess.PIPE,\n",
    "                                stderr = subprocess.PIPE)\n",
    "    (out, error) = git_pull.communicate()\n",
    "\n",
    "\n",
    "    print(\"Error : \" + str(error))\n",
    "    print(\"out : \" + str(out))\n",
    "\n",
    "\n",
    "def get_current_data_germany():\n",
    "    # 16 states\n",
    "    #data=requests.get('https://services7.arcgis.com/mOBPykOjAyBO2ZKk/arcgis/rest/services/Coronaf%C3%A4lle_in_den_Bundesl%C3%A4ndern/FeatureServer/0/query?where=1%3D1&outFields=*&outSR=4326&f=json')\n",
    "\n",
    "    # 400 regions/ Landkreise\n",
    "    data=requests.get('https://services7.arcgis.com/mOBPykOjAyBO2ZKk/arcgis/rest/services/RKI_Landkreisdaten/FeatureServer/0/query?where=1%3D1&outFields=*&outSR=4326&f=json')\n",
    "    json_object=json.loads(data.content)\n",
    "    full_list=[]\n",
    "    for pos,each_dict in enumerate (json_object['features'][:]):\n",
    "        full_list.append(each_dict['attributes'])\n",
    "\n",
    "        pd_full_list=pd.DataFrame(full_list)\n",
    "        pd_full_list.to_csv('C:/Users/Nitin/ds-covid19/data/raw/NPGEO/Ger_state_data.csv',sep=':')\n",
    "        #print('Number of regions rows: '+str(pd_full_list.shape[0]))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    get_johns_hopkins()\n",
    "    get_current_data_germany()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Process Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest date is2020-09-14 00:00:00\n",
      " Number of rows stored: 237\n"
     ]
    }
   ],
   "source": [
    "# %load C:\\Users\\Nitin\\ds-covid19\\src\\data\\process_combined_data.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def store_relational_JH_data():\n",
    "    data_path='C:/Users/Nitin/ds-covid19/data/raw/COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "    pd_raw=pd.read_csv(data_path)\n",
    "\n",
    "    pd_data_base=pd_raw.rename(columns={'Country/Region':'country',\n",
    "                                   'Province/State':'state'})\n",
    "    pd_data_base['state']=pd_data_base['state'].fillna('no')\n",
    "    pd_data_base=pd_data_base.drop(['Lat','Long'],axis=1)\n",
    "\n",
    "\n",
    "    pd_relational_model=pd_data_base.set_index(['state','country'])\\\n",
    "                                .T                             \\\n",
    "                                .stack(level=[0,1])            \\\n",
    "                                .reset_index()                 \\\n",
    "                                .rename(columns={'level_0':'date',\n",
    "                                                0:'confirmed'},\n",
    "                                               )\n",
    "\n",
    "    pd_relational_model['date']=pd_relational_model.date.astype('datetime64[ns]')\n",
    "\n",
    "    pd_relational_model.to_csv('C:/Users/Nitin/ds-covid19/data/processed/COVID_relational_confirmed.csv',sep=';')\n",
    "    #print(' Number of rows stored: '+str(pd_relational_model.shape[0]))\n",
    "    #print(' Latest date is: '+str(max(pd_relational_model.date)))\n",
    "\n",
    "def store_flat_table_JH_data():\n",
    "    \"process raw JH data into a flat table data structure\"\n",
    "    datapath='C:/Users/Nitin/ds-covid19/data/raw/COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "    JH_data_raw=pd.read_csv(datapath)\n",
    "    time_index=JH_data_raw.columns[4:]\n",
    "    pd_flat_table=pd.DataFrame({'date':time_index})\n",
    "    country_list=JH_data_raw['Country/Region'].unique()\n",
    "    for country in country_list:\n",
    "        pd_flat_table[country]=np.array(JH_data_raw[JH_data_raw['Country/Region']==country].iloc[:,4::].sum(axis=0))\n",
    "    time_index=[datetime.strptime(each,\"%m/%d/%y\") for each in pd_flat_table.date]\n",
    "    pd_flat_table['date']=time_index\n",
    "    pd_flat_table.to_csv('C:/Users/Nitin/ds-covid19/data/processed/COVID_JH_flat_table_confirmed.csv',sep=';',index=False )\n",
    "    print('Latest date is'+str(max(pd_flat_table.date)))\n",
    "    print(' Number of rows stored: '+str(pd_flat_table.shape[0]))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    store_relational_JH_data()\n",
    "    store_flat_table_JH_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Filter and Doubling Rate Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the test slope is: [2.]\n",
      "      Unnamed: 0        date state  country  confirmed  confirmed_filtered  \\\n",
      "34360      61856  2020-09-10    no  Germany   258149.0            258018.2   \n",
      "34361      62122  2020-09-11    no  Germany   259735.0            259374.2   \n",
      "34362      62388  2020-09-12    no  Germany   260817.0            260732.0   \n",
      "34363      62654  2020-09-13    no  Germany   261737.0            261946.8   \n",
      "34364      62920  2020-09-14    no  Germany   263222.0            263161.6   \n",
      "\n",
      "       confirmed_DR  confirmed_filtered_DR  \n",
      "34360    160.722431             168.789051  \n",
      "34361    156.332930             184.661656  \n",
      "34362    194.577961             191.152480  \n",
      "34363    260.502498             202.662158  \n",
      "34364    217.817325             215.629569  \n"
     ]
    }
   ],
   "source": [
    "# %load C:\\Users\\Nitin\\ds-covid19\\src\\features\\build_features.py\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression(fit_intercept=True)\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "def get_doubling_time_via_regression(in_array):\n",
    "    ''' Use a linear regression to approximate the doubling rate\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        in_array : pandas.series\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        Doubling rate: double\n",
    "    '''\n",
    "\n",
    "    y = np.array(in_array)\n",
    "    X = np.arange(-1,2).reshape(-1, 1)\n",
    "\n",
    "    assert len(in_array)==3\n",
    "    reg.fit(X,y)\n",
    "    intercept=reg.intercept_\n",
    "    slope=reg.coef_\n",
    "\n",
    "    return intercept/slope\n",
    "\n",
    "\n",
    "def savgol_filter(df_input,column='confirmed',window=5):\n",
    "    ''' Savgol Filter which can be used in groupby apply function (data structure kept)\n",
    "\n",
    "        parameters:\n",
    "        ----------\n",
    "        df_input : pandas.series\n",
    "        column : str\n",
    "        window : int\n",
    "            used data points to calculate the filter result\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_result: pd.DataFrame\n",
    "            the index of the df_input has to be preserved in result\n",
    "    '''\n",
    "\n",
    "    degree=1\n",
    "    df_result=df_input\n",
    "\n",
    "    filter_in=df_input[column].fillna(0) # attention with the neutral element here\n",
    "\n",
    "    result=signal.savgol_filter(np.array(filter_in),\n",
    "                           window, # window size used for filtering\n",
    "                           1)\n",
    "    df_result[str(column+'_filtered')]=result\n",
    "    return df_result\n",
    "\n",
    "def rolling_reg(df_input,col='confirmed'):\n",
    "    ''' Rolling Regression to approximate the doubling time'\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        col: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        result: pd.DataFrame\n",
    "    '''\n",
    "    days_back=3\n",
    "    result=df_input[col].rolling(\n",
    "                window=days_back,\n",
    "                min_periods=days_back).apply(get_doubling_time_via_regression,raw=False)\n",
    "\n",
    "\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calc_filtered_data(df_input,filter_on='confirmed'):\n",
    "    '''  Calculate savgol filter and return merged data frame\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        filter_on: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_output: pd.DataFrame\n",
    "            the result will be joined as a new column on the input data frame\n",
    "    '''\n",
    "\n",
    "    must_contain=set(['state','country',filter_on])\n",
    "    assert must_contain.issubset(set(df_input.columns)), ' Error in calc_filtered_data not all columns in data frame'\n",
    "\n",
    "    df_output=df_input.copy() # we need a copy here otherwise the filter_on column will be overwritten\n",
    "\n",
    "    pd_filtered_result=df_output[['state','country',filter_on]].groupby(['state','country']).apply(savgol_filter)#.reset_index()\n",
    "\n",
    "    #print('--+++ after group by apply')\n",
    "    #print(pd_filtered_result[pd_filtered_result['country']=='Germany'].tail())\n",
    "\n",
    "    #df_output=pd.merge(df_output,pd_filtered_result[['index',str(filter_on+'_filtered')]],on=['index'],how='left')\n",
    "    df_output=pd.merge(df_output,pd_filtered_result[[str(filter_on+'_filtered')]],left_index=True,right_index=True,how='left')\n",
    "    #print(df_output[df_output['country']=='Germany'].tail())\n",
    "    return df_output.copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calc_doubling_rate(df_input,filter_on='confirmed'):\n",
    "    ''' Calculate approximated doubling rate and return merged data frame\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        filter_on: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_output: pd.DataFrame\n",
    "            the result will be joined as a new column on the input data frame\n",
    "    '''\n",
    "\n",
    "    must_contain=set(['state','country',filter_on])\n",
    "    assert must_contain.issubset(set(df_input.columns)), ' Error in calc_filtered_data not all columns in data frame'\n",
    "\n",
    "\n",
    "    pd_DR_result= df_input.groupby(['state','country']).apply(rolling_reg,filter_on).reset_index()\n",
    "\n",
    "    pd_DR_result=pd_DR_result.rename(columns={filter_on:filter_on+'_DR',\n",
    "                             'level_2':'index'})\n",
    "\n",
    "    #we do the merge on the index of our big table and on the index column after groupby\n",
    "    df_output=pd.merge(df_input,pd_DR_result[['index',str(filter_on+'_DR')]],left_index=True,right_on=['index'],how='left')\n",
    "    df_output=df_output.drop(columns=['index'])\n",
    "\n",
    "\n",
    "    return df_output\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_data_reg=np.array([2,4,6])\n",
    "    result=get_doubling_time_via_regression(test_data_reg)\n",
    "    print('the test slope is: '+str(result))\n",
    "\n",
    "    pd_JH_data=pd.read_csv('C:/Users/Nitin/ds-covid19/data/processed/COVID_relational_confirmed.csv',sep=';',parse_dates=[0])\n",
    "    pd_JH_data=pd_JH_data.sort_values('date',ascending=True).copy()\n",
    "\n",
    "    #test_structure=pd_JH_data[((pd_JH_data['country']=='US')|\n",
    "    #                  (pd_JH_data['country']=='Germany'))]\n",
    "\n",
    "    pd_result_larg=calc_filtered_data(pd_JH_data)\n",
    "    pd_result_larg=calc_doubling_rate(pd_result_larg)\n",
    "    pd_result_larg=calc_doubling_rate(pd_result_larg,'confirmed_filtered')\n",
    "\n",
    "\n",
    "    mask=pd_result_larg['confirmed']>100\n",
    "    pd_result_larg['confirmed_filtered_DR']=pd_result_larg['confirmed_filtered_DR'].where(mask, other=np.NaN)\n",
    "    pd_result_larg.to_csv('C:/Users/Nitin/ds-covid19/data/processed/COVID_final_set.csv',sep=';',index=False)\n",
    "    print(pd_result_larg[pd_result_larg['country']=='Germany'].tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visual Board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\CVT\\SS20\\DataScience\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: on\n"
     ]
    }
   ],
   "source": [
    "# %load C:\\Users\\Nitin\\ds-covid19\\src\\visualization\\visualization_combined.py \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import dash\n",
    "dash.__version__\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input,Output\n",
    "import dash_bootstrap_components as dbc\n",
    "import plotly.io as pio\n",
    "\n",
    "import os\n",
    "print(os.getcwd())\n",
    "df_input_large=pd.read_csv('C:/Users/Nitin/ds-covid19/data/processed/COVID_final_set.csv',sep=';')\n",
    "df_SIR_large=pd.read_csv('C:/Users/Nitin/ds-covid19/data/processed/COVID_JH_flat_table_confirmed.csv',sep=';',parse_dates=[0])\n",
    "df_SIR_large=df_SIR_large.sort_values('date',ascending=True)\n",
    "\n",
    "fig=go.Figure()\n",
    "app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "\n",
    "app.title = 'COVID-19 Dashboard based on Applied Data Science'\n",
    "\n",
    "app.layout = html.Div([\n",
    "\n",
    "        dbc.Row(dbc.Col(html.H1('COVID-19 Data Dashboard Visualization using Applied Data Science'),\n",
    "                        width={'size': 8, 'offset': 1},\n",
    "                        ),\n",
    "                ),\n",
    "\n",
    "        dbc.Row(dbc.Col(html.Div('''\n",
    "                            Goal of the project is to teach data science by applying a cross industry standard process,\n",
    "                            it covers the full walkthrough of: automated data gathering, data transformations,\n",
    "                            filtering and machine learning to approximating the doubling time, and\n",
    "                            (static) deployment of responsive dashboard alongwith SIR simulation.\n",
    "                            '''),\n",
    "                        width={'size': 8, 'offset': 1},\n",
    "                        )\n",
    "                ),\n",
    "\n",
    "\n",
    "       dbc.Row(dbc.Col(html.H5('Select a single country for SIR simulation curve'),\n",
    "                        width={'size': 5, 'offset': 1},\n",
    "                        ),\n",
    "                ),\n",
    "\n",
    "        dbc.Row(\n",
    "        [\n",
    "                  dbc.Col(\n",
    "\n",
    "                        dcc.Dropdown( id='single_select_country',\n",
    "                             options=[{'label':each,'value':each} for each in df_SIR_large.columns[1:]],\n",
    "                             value='Germany',\n",
    "                             multi=False),\n",
    "                             width={'size': 5, \"offset\": 1, 'order': 'second'}),\n",
    "            ],\n",
    "        ),\n",
    "\n",
    "\n",
    "        dbc.Row(dbc.Col(html.H5('In order to manipulate the SIR curve, vary the values regarding the measures and press enter:'),\n",
    "                        width={'size': 5, 'offset': 1},\n",
    "                        ),\n",
    "                ),\n",
    "\n",
    "\n",
    "        dbc.Row(\n",
    "        [\n",
    "\n",
    "            #For changing beta ,gamma, t_initial, t_intro_measures,t_hold,t_relax\n",
    "            dbc.Row(children=[\n",
    "            html.Br(),\n",
    "            html.Br(),\n",
    "            html.Label([\"No measures introduced (in days):\",\n",
    "                      dcc.Input(id='t_initial',\n",
    "                     type='number',\n",
    "                     value=28,debounce=True)],style={\"margin-left\": \"30px\"}),\n",
    "            html.Label([\"Measures introduced over (in days):\",\n",
    "                      dcc.Input(id='t_intro_measures',\n",
    "                     type='number',\n",
    "                     value=14,debounce=True)],style={\"margin-left\": \"30px\"}),\n",
    "            html.Label([\"Introduced measures hold time (in days):\",\n",
    "                      dcc.Input(id='t_hold',\n",
    "                     type='number',\n",
    "                     value=21,debounce=True)],style={\"margin-left\": \"30px\"}),\n",
    "            html.Br(),\n",
    "            html.Br(),\n",
    "            html.Label([\"Introduced measures relaxed (in days):\",\n",
    "                      dcc.Input(id='t_relax',\n",
    "                     type='number',\n",
    "                     value=21,debounce=True)],style={\"margin-left\": \"30px\"}),\n",
    "            html.Label([\"Beta max:\",\n",
    "                      dcc.Input(id='beta_max',\n",
    "                     type='number',\n",
    "                     value=0.4,debounce=True)],style={\"margin-left\": \"30px\"}),\n",
    "            html.Label([\"Beta min:\",\n",
    "                      dcc.Input(id='beta_min',\n",
    "                     type='number',\n",
    "                     value=0.11,debounce=True)],style={\"margin-left\": \"30px\"}),\n",
    "            html.Label([\"Gamma:\",\n",
    "                      dcc.Input(id='gamma',\n",
    "                     type='number',\n",
    "                     value=0.1,debounce=True)],style={\"margin-left\": \"30px\"}),\n",
    "            html.Br(),\n",
    "            html.Br(),\n",
    "            ]\n",
    "            ),\n",
    "\n",
    "\n",
    "                dbc.Col(dcc.Graph(\n",
    "                            figure=fig,\n",
    "                            id='SIR_curve'),\n",
    "                        width=6, md={'size': 10,  \"offset\": 1, 'order': 'last'}\n",
    "                        ),\n",
    "            ]\n",
    "        ),\n",
    "\n",
    "         dbc.Row(dbc.Col(html.H5('Multi - Select Country for Visualization'),\n",
    "                        width={'size': 5, 'offset': 1},\n",
    "                        ),\n",
    "                ),\n",
    "\n",
    "\n",
    "        dbc.Row(\n",
    "            [\n",
    "                dbc.Col(\n",
    "                       dcc.Dropdown(\n",
    "                      id='country_drop_down',\n",
    "                      options=[ {'label': each,'value':each} for each in df_input_large['country'].unique()],\n",
    "                      value=['US', 'Germany','Italy'], # which are pre-selected\n",
    "                      multi=True),\n",
    "                      width={'size': 5, \"offset\": 1, 'order': 'first'}\n",
    "                     ),\n",
    "\n",
    "                ], no_gutters=True\n",
    "        ),\n",
    "\n",
    "      dbc.Row(dbc.Col(html.H5('Select Timeline of confirmed COVID-19 cases or the approximated doubling time'),\n",
    "                        width={'size': 5, 'offset': 1},\n",
    "                        ),\n",
    "                ),\n",
    "\n",
    "\n",
    "        dbc.Row(\n",
    "            [\n",
    "                dbc.Col(\n",
    "\n",
    "\n",
    "                dcc.Dropdown(\n",
    "                id='doubling_time',\n",
    "                options=[\n",
    "                    {'label': 'Timeline Confirmed ', 'value': 'confirmed'},\n",
    "                    {'label': 'Timeline Confirmed Filtered', 'value': 'confirmed_filtered'},\n",
    "                    {'label': 'Timeline Doubling Rate', 'value': 'confirmed_DR'},\n",
    "                    {'label': 'Timeline Doubling Rate Filtered', 'value': 'confirmed_filtered_DR'},\n",
    "                ],\n",
    "                value='confirmed',\n",
    "                multi=False),\n",
    "                width={'size': 3, \"offset\": 1, 'order': 'first'}\n",
    "                        ),\n",
    "\n",
    "             ],\n",
    "        ),\n",
    "\n",
    "        dbc.Row(\n",
    "            [\n",
    "                dbc.Col(dcc.Graph(\n",
    "                            id='main_window_slope'\n",
    "                            ),\n",
    "                        width=6, md={'size': 8,  \"offset\": 1, 'order': 'first'}\n",
    "                        ),\n",
    "\n",
    "                ],\n",
    "            ),\n",
    " ])\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('SIR_curve', 'figure'),\n",
    "    [Input('single_select_country', 'value'),\n",
    "    Input('t_initial','value'),\n",
    "    Input('t_intro_measures','value'),\n",
    "    Input('t_hold','value'),\n",
    "    Input('t_relax','value'),\n",
    "    Input('beta_max','value'),\n",
    "    Input('beta_min','value'),\n",
    "    Input('gamma','value')])\n",
    "\n",
    "\n",
    "def SIR_figure(country,initial_time,intro_measures,hold_time,relax_time,max_beta,min_beta,gamma_max):\n",
    "    ydata=df_SIR_large[country][df_SIR_large[country]>=30]\n",
    "    xdata=np.arange(len(ydata))\n",
    "    N0=5000000\n",
    "    I0=30\n",
    "    S0=N0-I0\n",
    "    R0=0\n",
    "    gamma=gamma_max\n",
    "    SIR=np.array([S0,I0,R0])\n",
    "\n",
    "    t_initial=initial_time\n",
    "    t_intro_measures=intro_measures\n",
    "    t_hold=hold_time\n",
    "    t_relax=relax_time\n",
    "    beta_max=max_beta\n",
    "    beta_min=min_beta\n",
    "    propagation_rates=pd.DataFrame(columns={'susceptible':S0,'infected':I0,'recovered':R0})\n",
    "    pd_beta=np.concatenate((np.array(t_initial*[beta_max]),\n",
    "                       np.linspace(beta_max,beta_min,t_intro_measures),\n",
    "                       np.array(t_hold*[beta_min]),\n",
    "                       np.linspace(beta_min,beta_max,t_relax),\n",
    "                       ))\n",
    "\n",
    "    def SIR_model(SIR,beta,gamma):\n",
    "        'SIR model for simulating spread'\n",
    "        'S: Susceptible population'\n",
    "        'I: Infected popuation'\n",
    "        'R: Recovered population'\n",
    "        'S+I+R=N (remains constant)'\n",
    "        'dS+dI+dR=0 model has to satisfy this condition at all time'\n",
    "        S,I,R=SIR\n",
    "        dS_dt=-beta*S*I/N0\n",
    "        dI_dt=beta*S*I/N0-gamma*I\n",
    "        dR_dt=gamma*I\n",
    "        return ([dS_dt,dI_dt,dR_dt])\n",
    "\n",
    "    for each_beta in pd_beta:\n",
    "        new_delta_vec=SIR_model(SIR,each_beta,gamma)\n",
    "        SIR=SIR+new_delta_vec\n",
    "        propagation_rates=propagation_rates.append({'susceptible':SIR[0],'infected':SIR[1],'recovered':SIR[2]},ignore_index=True)\n",
    "\n",
    "    fig=go.Figure()\n",
    "    fig.add_trace(go.Bar(x=xdata,\n",
    "                         y=ydata,\n",
    "                         marker=dict(color='Lightseagreen'),\n",
    "                         name='Confirmed Cases'\n",
    "                        ))\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=xdata,\n",
    "                            y=propagation_rates.infected,\n",
    "                            mode='lines',\n",
    "                            marker=dict(color='DarkRed'),\n",
    "                            name='Simulated curve'))\n",
    "\n",
    "    fig.update_layout(shapes=[\n",
    "                            dict(type='rect',xref='x',yref='paper',x0=0,y0=0,x1=t_initial,y1=1,fillcolor=\"MediumPurple\",opacity=0.4,layer=\"below\",line_width=0,),\n",
    "                            dict(type='rect',xref='x',yref='paper',x0=t_initial,y0=0,x1=t_initial+t_intro_measures,y1=1,fillcolor=\"MediumPurple\",opacity=0.5,layer=\"below\",line_width=0,),\n",
    "                            dict(type='rect',xref='x',yref='paper',x0=t_initial+t_intro_measures,y0=0,x1=t_initial+t_intro_measures+t_hold,y1=1,fillcolor=\"MediumPurple\",opacity=0.6,layer='below',line_width=0,),\n",
    "                            dict(type='rect',xref='x',yref='paper',x0=t_initial+t_intro_measures+t_hold,y0=0,x1=t_initial+t_intro_measures+t_hold+t_relax,y1=1,fillcolor='MediumPurple',opacity=0.7,layer='below',line_width=0,)\n",
    "                            ],\n",
    "                    title='SIR Simulation Model for COVID19',\n",
    "                    title_x=0.5,\n",
    "                    xaxis=dict(title='Time (in days)',\n",
    "                               titlefont_size=16),\n",
    "                    yaxis=dict(title='Confirmed cases based on Johns Hopkins Data, log scale ',\n",
    "                               type='log',\n",
    "                                titlefont_size=16,\n",
    "                              ),\n",
    "                    width=1280,\n",
    "                    height=600,\n",
    "                     )\n",
    "    return fig\n",
    "\n",
    "@app.callback(\n",
    "     Output('main_window_slope', 'figure'),\n",
    "     [Input('country_drop_down', 'value'),\n",
    "     Input('doubling_time', 'value')])\n",
    "def update_figure(country_list,show_doubling):\n",
    "\n",
    "\n",
    "     if 'doubling_rate' in show_doubling:\n",
    "         my_yaxis={'type':\"log\",\n",
    "                'title':'Approximated doubling rate over 3 days (larger numbers are better #stayathome)'\n",
    "               }\n",
    "     else:\n",
    "         my_yaxis={'type':\"log\",\n",
    "                   'title':'Confirmed infected people (source johns hopkins csse, log-scale)'\n",
    "               }\n",
    "\n",
    "\n",
    "     traces = []\n",
    "     for each in country_list:\n",
    "\n",
    "         df_plot=df_input_large[df_input_large['country']==each]\n",
    "\n",
    "         if show_doubling=='doubling_rate_filtered':\n",
    "             df_plot=df_plot[['state','country','confirmed','confirmed_filtered','confirmed_DR','confirmed_filtered_DR','date']].groupby(['country','date']).agg(np.mean).reset_index()\n",
    "         else:\n",
    "             df_plot=df_plot[['state','country','confirmed','confirmed_filtered','confirmed_DR','confirmed_filtered_DR','date']].groupby(['country','date']).agg(np.sum).reset_index()\n",
    "        #print(show_doubling)\n",
    "\n",
    "\n",
    "         traces.append(dict(x=df_plot.date,\n",
    "                                 y=df_plot[show_doubling],\n",
    "                                 mode='markers+lines',\n",
    "                                 opacity=0.9,\n",
    "                                 name=each\n",
    "                         )\n",
    "                 )\n",
    "\n",
    "     return {\n",
    "             'data': traces,\n",
    "             'layout': dict (\n",
    "                 height=720,\n",
    "\n",
    "                 xaxis={'title':'Timeline',\n",
    "                         'tickangle':-45,\n",
    "                         'nticks':20,\n",
    "                         'tickfont':dict(size=14,color=\"#7f7f7f\"),\n",
    "                       },\n",
    "\n",
    "                 yaxis=my_yaxis\n",
    "         )\n",
    "     }\n",
    "if __name__ == '__main__':\n",
    "     app.run_server(debug=True,use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
